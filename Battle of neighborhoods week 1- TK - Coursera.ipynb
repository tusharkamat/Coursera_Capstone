{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "DATA DESCRIPTION\nFor this problem, we will get the services of Foursquare API to explore the data of two cities, in terms of their neighborhoods. The data also include the information about the places around each neighborhood like restaurants, hotels, coffee shops, parks, theaters, art galleries, museums and many more. We selected one Borough from each city to analyze their neighborhoods. Manhattan from New York and Downtown Toronto from Toronto. We will use machine learning technique, \u201cClustering\u201d to segment the neighborhoods with similar objects on the basis of each neighborhood data. These objects will be given priority on the basis of foot traffic (activity) in their respective neighborhoods. This will help to locate the tourist\u2019s areas and hubs, and then we can judge the similarity or dissimilarity between two cities on that basis.\n\npath='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\nMETHODOLOGY\nAs we have selected two cities Borough to explore their neighborhoods. The data exploration, analysis and visualization for both boroughs are done in the same way but separately.\n\nEXPLORATION\nFor Downtown Toronto case, we have extracted table of Toronto\u2019s Borough from Wikipedia page. Then we arrange the data according to our requirements. In the arrangement phase, which applied multiple steps including but not limited to, eliminating \u201cNot assigned\u201d values, combine neighborhoods which have same geographical coordinates at each borough and sorted against the concerned borough. For data verification and further exploration, we use Foursquare API to get the coordinates of Downtown Toronto and explore its neighborhoods. The neighborhoods are further characterized as venues and venue categories. For Manhattan, we used a saved data file which is already explored through foursquare API in which we have extracted all the boroughs of New York and then sorted against the concerned borough. Then we explored the Manhattan neighborhoods as venues and venue categories\n"}, {"metadata": {}, "cell_type": "code", "source": "!pip install beautifulsoup4\n!pip install lxml", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: beautifulsoup4 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (4.9.1)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from beautifulsoup4) (2.0.1)\nRequirement already satisfied: lxml in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (4.5.1)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n#!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library\n\nprint('Libraries imported.')\n", "execution_count": null, "outputs": [{"output_type": "stream", "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nCollecting package metadata (repodata.json): done\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\nSolving environment: \\ ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Link To Extract\npath='https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n# Read File\ndf_wiki=pd.read_html(path)\n#Check the type\ntype(df_wiki)\n# Call the position where the table is stored\nneighborhood=df_wiki[0]\n# Rename the Columns\nneighborhood.rename(columns={0:'Postcode', 1: 'Borough', 2: 'Neighborhood'}, inplace=True)\n# Eliminate the first row\nneighborhood=neighborhood.drop([0])\n# Eliminate \"Not assigned\", categorical values from \"Borough\" Column\nneighborhood=neighborhood[neighborhood.Borough !='Not assigned']\n# Making DataFrame\nneighborhood=pd.DataFrame(neighborhood)\n# Merging rows with same Postcode\nneighborhood.set_index(['Postcode','Borough'],inplace=True)\nmerge_result = neighborhood.groupby(level=['Postcode','Borough'], sort=False).agg( ','.join)\n# Setting the index\nserial_wise=merge_result.reset_index()\n# Assign the 'Borough' column value to 'Neighborhood' where 'Not assigned' occurs\nserial_wise.loc[4, 'Neighborhood']='Queen\\'s Park'\n# Saving the file for future use!\nserial_wise.to_excel('wikipedia_table.xls')\n# Showing the Data Frame\ndf=pd.DataFrame(serial_wise)\ndf.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\ncsv_url = 'https://cocl.us/Geospatial_data'\ndf_location = pd.read_csv(csv_url)\ndf_location.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nfrom bs4 import BeautifulSoup", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nwiki_Toronto_postal_codes = 'https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M'\n# get page text and parse using BeautifulSoup\nsource = requests.get(wiki_Toronto_postal_codes).text\nsoup = BeautifulSoup(source, 'lxml')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# table with data\npcode_table = soup.find('table',{'class':'wikitable sortable'})\ntable_data = []\n# find all table rows\nfor tr in pcode_table.find_all('tr'):\n    row = []\n    # find all cells within row\n    for td in tr.find_all('td'):\n        # append extracted and trimmed cell text into row data  \n        row.append(td.get_text(strip=True))\n    # skip adding row to table_data in case is empty (header row)\n    if len(row):\n        table_data.append(row)\n# create data frame from list of lists\ndf_wiki = pd.DataFrame(data=table_data, columns=['PostalCode', 'Borough', 'Neighbourhood'])\n# filter out rows with Borough equal to 'Not assigned'\ndf_wiki = df_wiki[df_wiki.Borough != 'Not assigned']\ndf_wiki.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "df_wiki.loc[df_wiki['Neighbourhood'] == 'Not assigned','Neighbourhood'] = df_wiki['Borough']\ndf_grouped = df_wiki.groupby(['PostalCode', 'Borough'])['Neighbourhood'].apply(lambda neighbourhoods: ', '.join(neighbourhoods)).to_frame().reset_index()\ndf_grouped.head(5)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.7", "language": "python"}, "language_info": {"name": "python", "version": "3.7.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}